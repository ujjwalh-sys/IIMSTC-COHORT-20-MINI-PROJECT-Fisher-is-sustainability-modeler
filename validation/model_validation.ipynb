import numpy as np
from sklearn.metrics import mean_squared_error, r2_score

def evaluate_model(model, X_train, y_train, X_test, y_test):

    print("========== MODEL VALIDATION REPORT ==========\n")

    train_pred = model.predict(X_train)
    test_pred  = model.predict(X_test)

    train_rmse = np.sqrt(mean_squared_error(y_train, train_pred))
    test_rmse  = np.sqrt(mean_squared_error(y_test, test_pred))
    r2 = r2_score(y_test, test_pred)

    print(f"Train RMSE : {train_rmse:.2f}")
    print(f"Test RMSE  : {test_rmse:.2f}")
    print(f"R2 Score   : {r2:.4f}")

    if train_rmse < test_rmse:
        print("\nâš  Possible Overfitting Detected")
    else:
        print("\nModel Generalization Looks Stable")

    residuals = y_test - test_pred
    print("\nResidual Mean:", residuals.mean())
    print("Residual Std :", residuals.std())

    print("\n============================================\n")

    return train_rmse, test_rmse, r2
